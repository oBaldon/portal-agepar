---
id: testes-de-api-curl-pytest-e-exemplos
title: "Testes de API (cURL/pytest) e exemplos"
sidebar_position: 1
---

O Portal AGEPAR hoje Ã© testado principalmente com:

- **cURLs de fumaÃ§a** (descritos no `README.md`) para validar login, sessÃ£o e automations,
- **testes unitÃ¡rios sugeridos com pytest** para modelos Pydantic (jÃ¡ exemplificados em outras pÃ¡ginas de docs),
- e tem espaÃ§o aberto para **testes de API automatizados** usando `pytest + TestClient` (ainda nÃ£o criados no repositÃ³rio, mas jÃ¡ com padrÃ£o recomendado).

> ReferÃªncias no repo:
>
> - `README.md` â†’ seÃ§Ã£o **â€œðŸ§ª Testes rÃ¡pidos (cURL)â€**
> - `apps/bff/app/automations/*.py` â†’ endpoints de API das automations
> - `apps/bff/app/auth/routes.py` â†’ login, logout, sessÃµes
> - `apps/docs-site/docs/06-bff-fastapi/04-pydantic-v2-configdict-populate_by_name-extraignore.md` â†’ exemplos de **pytest** para modelos
> - `apps/docs-site/docs/06-bff-fastapi/05-normalizaÃ§Ã£o-validaÃ§Ã£o-evitar-422.md` â†’ mais exemplos de testes de normalizaÃ§Ã£o/validaÃ§Ã£o

---

## 1) Mapa mental: cURL vs pytest

```mermaid
flowchart LR
  Dev[(Dev)]
  subgraph CLI
    CURL["cURL scripts (manual/smoke)"]
    PYTEST["pytest (testes automatizados)"]
  end
  subgraph Stack
    BFF["FastAPI BFF :8000"]
    DB[(Postgres)]
  end

  Dev --> CURL
  Dev --> PYTEST
  CURL --> BFF
  PYTEST --> BFF
  BFF --> DB
````

* **cURL**: Ã³timo para smoke test rÃ¡pido, diagnÃ³stico e documentaÃ§Ã£o viva.
* **pytest**: ideal para cobrir casos de sucesso/erro de forma automatizada (incluindo o mesmo fluxo que os cURLs).

---

## 2) Testes rÃ¡pidos de API com cURL (do README)

A forma mais simples de validar se a stack estÃ¡ de pÃ©:

### 2.1. Login (mock) e sessÃ£o

Trechos retirados de `README.md`.

```bash title="Login (mock, ambiente dev)" showLineNumbers
curl -i -X POST http://localhost:8000/api/auth/login \
  -H 'Content-Type: application/json' \
  -d '{"identifier":"dev@example.com","password":"dev"}'
```

* Esperado: `HTTP/1.1 200 OK` + JSON com dados do usuÃ¡rio.
* O cookie `portal_agepar_session` deve ser setado no header `Set-Cookie`.

```bash title="SessÃ£o atual (/api/me)" showLineNumbers
curl -i http://localhost:8000/api/me
```

* Sem cookie â†’ `401 not authenticated`.
* Com cookie vÃ¡lido â†’ JSON com dados do usuÃ¡rio logado.

### 2.2. Teste rÃ¡pido de uma automaÃ§Ã£o simples (form2json)

Um exemplo de **teste de API completo** (do README e docs de BFF) Ã© a automaÃ§Ã£o `form2json`:

```bash title="Submit em /api/automations/form2json/submit" showLineNumbers
curl -i -X POST http://localhost:8000/api/automations/form2json/submit \
  -H 'Content-Type: application/json' \
  -d '{
    "fullName": "  Maria da Silva  ",
    "email": "  maria@example.com ",
    "phone": "(41) 9 9999-0000",
    "acceptTerms": "sim",
    "amount": "1.234,56",
    "dateStart": "18/11/2025"
  }'
```

O teste verifica que:

* a API responde com `200 OK`,
* o payload retornado jÃ¡ estÃ¡ **normalizado** (vide docs de Pydantic/normalizaÃ§Ã£o),
* nenhum `422 validation_error` Ã© disparado para casos triviais (espaÃ§os, formataÃ§Ã£o).

---

## 3) Pacote sugerido de cURLs de fumaÃ§a

Mesmo que apenas dois comandos estejam explÃ­citos no README, a **rotina sugerida** de smoke test Ã©:

1. **Healthcheck do BFF**

   ```bash title="Health do BFF" showLineNumbers
   curl -i http://localhost:8000/health
   ```

   * Esperado: `200 OK` + `{"status":"ok"}`.

2. **VersÃ£o e configuraÃ§Ã£o**

   ```bash title="/version" showLineNumbers
   curl -s http://localhost:8000/version | jq .
   ```

   * Confere `env`, `auth_mode`, `ep_mode`, `dfd_version`, `ferias_version`, `cors_origins` etc.

3. **Login + sessÃ£o**

   ```bash title="Login de dev e uso de sessÃ£o" showLineNumbers
   # login
   curl -i -c /tmp/cookies.txt \
     -X POST http://localhost:8000/api/auth/login \
     -H 'Content-Type: application/json' \
     -d '{"identifier":"dev@example.com","password":"dev"}'

   # /api/me usando cookie
   curl -i -b /tmp/cookies.txt http://localhost:8000/api/me
   ```

4. **Listagem de submissÃµes DFD (quando configurado)**

   ```bash title="Listar DFD do usuÃ¡rio" showLineNumbers
   curl -s -b /tmp/cookies.txt \
     "http://localhost:8000/api/automations/dfd/submissions?limit=5&offset=0" | jq .
   ```

5. **Submit DFD com payload mÃ­nimo**

   (exemplo simplificado; valores dependem da automaÃ§Ã£o)

   ```bash title="Submit DFD" showLineNumbers
   curl -i -b /tmp/cookies.txt \
     -X POST http://localhost:8000/api/automations/dfd/submit \
     -H 'Content-Type: application/json' \
     -d '{
       "modeloSlug": "padrao",
       "numero": "2025-001",
       "protocolo": "12345/2025",
       "assunto": "Teste de fumaÃ§a",
       "pcaAno": "2025"
     }'
   ```

6. **Exercitar um erro 4xx previsÃ­vel**

   ```bash title="DFD â€” forÃ§ar validation_error" showLineNumbers
   curl -i -b /tmp/cookies.txt \
     -X POST http://localhost:8000/api/automations/dfd/submit \
     -H 'Content-Type: application/json' \
     -d '{
       "modeloSlug": "padrao",
       "numero": "",
       "protocolo": "",
       "assunto": "",
       "pcaAno": "20"
     }'
   ```

   * Esperado: `422` com `{code: "validation_error", message: "...", details: ...}`
     (padrÃ£o descrito em **PadrÃµes de Erro & DX**).

> Esses cURLs podem ser agrupados em um script bash (ex.: `infra/scripts/smoke.sh`)
> para testes de fumaÃ§a pÃ³s-deploy.

---

## 4) pytest: onde entra e o que jÃ¡ estÃ¡ documentado

### 4.1. SituaÃ§Ã£o atual no repositÃ³rio

No zip atual:

* **nÃ£o hÃ¡** pastas de teste (`tests/`) nem arquivos `pytest.ini` / `conftest.py`,
* mas jÃ¡ existem **exemplos de uso de pytest nos docs**, especialmente:

  * `06-bff-fastapi/04-pydantic-v2-configdict-populate_by_name-extraignore.md`
  * `06-bff-fastapi/05-normalizaÃ§Ã£o-validaÃ§Ã£o-evitar-422.md`

Nesses docs, aparecem testes como:

```python title="Exemplo de teste (docs de Pydantic)" showLineNumbers
# tests/test_submit_payload.py
from pydantic import ValidationError
from app.automations.form2json import Body

def test_normalize_and_validate():
    b = Body(fullName="  Alice  ", email="  A@Example.com ")
    assert b.full_name == "Alice"
    assert b.email == "a@example.com"

def test_empty_name_fails():
    try:
        Body(fullName="  ")
    except ValidationError:
        ...
```

e:

```python title="Exemplo de testes de normalizaÃ§Ã£o" showLineNumbers
def test_trim_and_case():
    p = SubmitPayload(fullName="  maria da silva  ")
    assert p.full_name == "Maria Da Silva"

def test_phone_digits():
    assert SubmitPayload(fullName="a", phone="(41) 9 9999-0000").phone == "41999990000"
```

Ou seja:

* a **filosofia de testes** jÃ¡ estÃ¡ definida:

  * focar em normalizaÃ§Ã£o e validaÃ§Ã£o,
  * garantir que â€œo modelo faz o que prometeâ€,
* falta apenas **materializar isso em uma Ã¡rvore de testes pytest** no repo.

---

## 5) Estrutura recomendada para testes de API com pytest

Mesmo que ainda nÃ£o exista, o padrÃ£o recomendando para organizar testes Ã©:

```text
apps/
  bff/
    app/
      ...
    tests/
      __init__.py
      test_auth.py
      test_form2json.py
      test_dfd_api.py
      test_ferias_api.py
      conftest.py
```

### 5.1. `conftest.py` com TestClient

```python title="apps/bff/tests/conftest.py (sugestÃ£o)" showLineNumbers
import os
import pytest
from fastapi.testclient import TestClient

from app.main import APP  # FastAPI principal

@pytest.fixture(scope="session")
def client() -> TestClient:
    # Garantir que estamos em ambiente de teste
    os.environ.setdefault("ENV", "test")
    os.environ.setdefault("AUTH_MODE", "mock")
    return TestClient(APP)
```

### 5.2. Testes bÃ¡sicos de API (equivalentes aos cURLs)

#### Login + /api/me

```python title="apps/bff/tests/test_auth.py (sugestÃ£o)" showLineNumbers
def test_login_and_me(client: "TestClient"):
    # login mock
    res = client.post(
        "/api/auth/login",
        json={"identifier": "dev@example.com", "password": "dev"},
    )
    assert res.status_code == 200
    data = res.json()
    assert "cpf" in data
    assert "nome" in data

    # reaproveita cookies da sessÃ£o
    res_me = client.get("/api/me")
    assert res_me.status_code == 200
    me = res_me.json()
    assert me["cpf"] == data["cpf"]
```

#### validation_error em automaÃ§Ã£o

```python title="apps/bff/tests/test_dfd_api.py (sugestÃ£o)" showLineNumbers
def test_dfd_validation_error(client: "TestClient"):
    # login primeiro
    client.post(
        "/api/auth/login",
        json={"identifier": "dev@example.com", "password": "dev"},
    )

    res = client.post(
        "/api/automations/dfd/submit",
        json={
            "modeloSlug": "padrao",
            "numero": "",
            "protocolo": "",
            "assunto": "",
            "pcaAno": "20",
        },
    )
    assert res.status_code == 422
    body = res.json()
    assert body["code"] == "validation_error"
    assert "message" in body
    assert "details" in body
```

#### fluxo feliz de submit

```python title="Submit DFD ok" showLineNumbers
def test_dfd_submit_ok(client: "TestClient"):
    client.post(
        "/api/auth/login",
        json={"identifier": "dev@example.com", "password": "dev"},
    )

    res = client.post(
        "/api/automations/dfd/submit",
        json={
            "modeloSlug": "padrao",
            "numero": "2025-001",
            "protocolo": "12345/2025",
            "assunto": "Teste pytest",
            "pcaAno": "2025",
        },
    )
    assert res.status_code == 200
    data = res.json()
    assert "sid" in data
    assert data["status"] in ("queued", "done")
```

---

## 6) Como rodar pytest (quando testes forem criados)

Quando a pasta `apps/bff/tests/` existir, o fluxo sugerido Ã©:

```bash title="ExecuÃ§Ã£o de pytest (sugestÃ£o)" showLineNumbers
# dentro do container ou no seu Python local
cd apps/bff

# instalar dependÃªncias (se ainda nÃ£o fez)
pip install -r requirements.txt
pip install pytest

# rodar testes
pytest -q
```

E, para facilitar, pode ser criado um alvo de Make / script:

```bash title="Makefile (exemplo)" showLineNumbers
test-bff:
\tcd apps/bff && pytest -q
```

---

## 7) Cobrindo os contratos de erro (4xx/5xx) em pytest

A partir da seÃ§Ã£o de **PadrÃµes de Erro & DX**, os testes de API podem verificar:

* cÃ³digos HTTP certos,
* `code` correto no JSON,
* estrutura de `details`.

Exemplos:

```python title="Testando 403 forbidden" showLineNumbers
def test_dfd_forbidden_on_other_user_submission(client: "TestClient"):
    # login como usuÃ¡rio A, criar submissÃ£o...
    client.post("/api/auth/login", json={"identifier": "userA", "password": "dev"})
    res = client.post("/api/automations/dfd/submit", json={...})
    sid = res.json()["sid"]

    # login como usuÃ¡rio B
    client.post("/api/auth/login", json={"identifier": "userB", "password": "dev"})

    # tentar acessar submissÃ£o de A
    res = client.get(f"/api/automations/dfd/submissions/{sid}")
    assert res.status_code == 403
    body = res.json()
    assert body["code"] == "forbidden"
```

```python title="Testando storage_error em cenÃ¡rio de falha de DB (mock)" showLineNumbers
def test_dfd_storage_error(monkeypatch, client: "TestClient"):
    from app import db

    def fake_list_submissions(*args, **kwargs):
        raise RuntimeError("db down")

    monkeypatch.setattr(db, "list_submissions", fake_list_submissions)

    client.post("/api/auth/login", json={"identifier": "dev@example.com", "password": "dev"})

    res = client.get("/api/automations/dfd/submissions")
    assert res.status_code == 500
    body = res.json()
    assert body["code"] == "storage_error"
    assert "Falha ao consultar submissÃµes." in body["message"]
```

---

## 8) Checklist de testes de API (para cada automaÃ§Ã£o)

Para cada nova automaÃ§Ã£o (ou endpoint) criada, o ideal Ã© ter pelo menos:

1. **Smoke cURL** (documentado no README ou na prÃ³pria pÃ¡gina da automaÃ§Ã£o):

   * [ ] Login + submit.
   * [ ] Listagem de submissÃµes.
   * [ ] Download (quando aplicÃ¡vel).
   * [ ] Erro de validaÃ§Ã£o (422) com payload claramente invÃ¡lido.

2. **pytest de API** (quando a suÃ­te existir):

   * [ ] `test_submit_ok` (trilha feliz).
   * [ ] `test_validation_error` (422).
   * [ ] `test_forbidden` (403, com usuÃ¡rio sem permissÃ£o).
   * [ ] `test_not_found` (404 com SID inexistente).
   * [ ] `test_not_ready` / `submission_in_progress` (409, se aplicÃ¡vel).
   * [ ] `test_file_not_found` (410, se houver geraÃ§Ã£o de arquivos).

3. **pytest de modelos** (como jÃ¡ exibido nas docs de Pydantic):

   * [ ] NormalizaÃ§Ã£o (trim, lower, CPF, telefone, etc.).
   * [ ] Regras de negÃ³cio simples (perÃ­odo de datas, formatos vÃ¡lidos).

---

> _Criado em 2025-12-02_