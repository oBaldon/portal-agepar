---
id: backup-migraÃ§Ã£o-se-houver-e-limites
title: "Backup/migraÃ§Ã£o (se houver) e limites"
sidebar_position: 5
---

Esta pÃ¡gina amarra trÃªs assuntos relacionados Ã  **persistÃªncia** no Portal AGEPAR:

- Onde os dados vivem (PostgreSQL + diretÃ³rio de uploads).
- Como pensar em **backup/restore** e **migraÃ§Ã£o de schema**.
- Quais sÃ£o os **limites** jÃ¡ implementados (tamanho, TTL, paginaÃ§Ã£o, limpeza).

> ReferÃªncias principais no repositÃ³rio:  
> `infra/docker-compose.dev.yml`  
> `infra/docker-compose.pg.yml`  
> `infra/scripts/dev_down.sh`  
> `infra/scripts/dev_fresh.sh`  
> `infra/sql/init_db.sql`  
> `apps/bff/app/db.py`  
> `apps/bff/app/automations/fileshare.py`  

---

## 1) Onde os dados vivem

### 1.1. Banco de dados (PostgreSQL)

O banco padrÃ£o em dev Ã© um **Postgres 16** definido em:

- `infra/docker-compose.pg.yml`

Trechos relevantes:

```yaml title="infra/docker-compose.pg.yml (trecho simplificado)"
services:
  postgres:
    image: postgres:16-alpine
    container_name: portal-agepar-postgres
    environment:
      POSTGRES_DB: ${PGDATABASE:-portal}
      POSTGRES_USER: ${PGUSER:-portal}
      POSTGRES_PASSWORD: ${PGPASSWORD:-portaldev}
      TZ: UTC
      PGTZ: UTC
    ports:
      - "${PGPORT_MAP:-5432}:5432"
    # ... volumes, healthcheck, etc.

volumes:
  pg_data:
    labels:
      org.agepar.project: portal-agepar
      org.agepar.volume: pg_data
````

Pontos importantes:

* HÃ¡ um **volume nomeado** `pg_data` associado ao Postgres.
* Enquanto o volume existir, os dados do banco sÃ£o preservados, mesmo que o container
  seja destruÃ­do/recriado.
* O BFF se conecta via `DATABASE_URL` (construÃ­da a partir de `PG*`), e no startup
  roda `init_db()` (ver pÃ¡ginas anteriores) para garantir `submissions`,
  `automation_audits` e `fileshare_items`.

### 1.2. Arquivos de uploads (fileshare)

A automaÃ§Ã£o `fileshare` grava arquivos em disco (metadados vÃ£o para o Postgres):

* Caminho base configurado via `UPLOAD_ROOT` (default `/data/uploads`):

```python title="apps/bff/app/automations/fileshare.py (trecho)" showLineNumbers
UPLOAD_ROOT = Path(os.getenv("UPLOAD_ROOT", "/data/uploads")).resolve()
UPLOAD_ROOT.mkdir(parents=True, exist_ok=True)
```

Para que **backup/restore** faÃ§a sentido, Ã© preciso pensar sempre em **duas peÃ§as**:

1. O banco (`pg_data` / Postgres).
2. O diretÃ³rio de uploads (`UPLOAD_ROOT`, montado como volume ou bind no BFF).

---

## 2) Backups (dev e alÃ©m)

NÃ£o hÃ¡, hoje, um job automatizado de backup dentro do repositÃ³rio.
A responsabilidade Ã© da **infra** (cron, job de Kubernetes, ferramenta corporativa, etc.).

Mesmo assim, o repo jÃ¡ facilita alguns fluxos.

### 2.1. Dev local (uso de laboratÃ³rio)

Em dev, a abordagem tÃ­pica Ã©:

* **Sem SLA de backup**: o banco Ã© considerado â€œdescartÃ¡velâ€.
* Scripts que **apagam tudo** (inclusive DB) sÃ£o parte do fluxo:

`infra/scripts/dev_down.sh`:

```bash title="infra/scripts/dev_down.sh" showLineNumbers
docker compose \
  -f "${INFRA_DIR}/docker-compose.dev.yml" \
  -f "${INFRA_DIR}/docker-compose.pg.yml" \
  down -v

echo "ðŸ›‘ Stack dev+pg derrubado e volumes removidos."
```

> `down -v` remove containers **e volumes** â†’ inclusive o `pg_data`.

`infra/scripts/dev_fresh.sh`:

```bash title="dev_fresh.sh (cabeÃ§alho)" showLineNumbers
# Uso:
#   ./infra/scripts/dev_fresh.sh           # zera tudo, inclusive DB (pg_data)
#   ./infra/scripts/dev_fresh.sh --keep-db # preserva DB, zera containers e imagens
```

Ou seja:

* Se rodar `dev_down.sh` ou `dev_fresh.sh` sem `--keep-db`, o banco dev vai embora.
* Se quiser preservar dados de dev, use:

  * `dev_fresh.sh --keep-db` **ou**
  * `docker compose ... down` **sem** `-v`.

Mesmo em dev, se quiser â€œtirar um snapshotâ€ antes de quebrar tudo:

```bash title="Dump rÃ¡pido do banco dev" showLineNumbers
# Dump lÃ³gico do banco 'portal' para um arquivo .sql
docker exec -i portal-agepar-postgres \
  pg_dump -U "${PGUSER:-portal}" "${PGDATABASE:-portal}" \
  > backup-portal-dev-$(date +%F).sql
```

### 2.2. Homolog / ProduÃ§Ã£o (recomendaÃ§Ã£o)

Para ambientes â€œde verdadeâ€, o recomendÃ¡vel Ã©:

1. **Backup lÃ³gico diÃ¡rio** com `pg_dump`:

   * Full dump (`pg_dump`) ou schema + dados crÃ­ticos.
   * Solo ou via ferramentas (pgBackRest, Barman, etc.).
2. **RetenÃ§Ã£o definida** (ex.: 30 dias de diÃ¡rios + 6 meses de semanais).
3. **InclusÃ£o do diretÃ³rio de uploads** (`UPLOAD_ROOT`):

   * backup de filesystem (tar, snapshot de volume, etc.),
   * com retenÃ§Ã£o alinhada ao banco.

Exemplo de comando lÃ³gico (ajuste para sua infra):

```bash title="Exemplo conceitual para cron" showLineNumbers
PGURL="postgresql://portal:***@postgres:5432/portal"
pg_dump "$PGURL" | gzip > /backup/portal-agepar-$(date +%F).sql.gz

# Em paralelo, backup do diretÃ³rio de uploads
tar czf /backup/uploads-$(date +%F).tar.gz /data/uploads
```

> **DecisÃ£o de produto:** o Portal AGEPAR **nÃ£o** tenta fazer backup por conta prÃ³pria.
> A suposiÃ§Ã£o Ã© que o banco (e volumes) estÃ£o sob uma polÃ­tica corporativa de backup.

---

## 3) MigraÃ§Ã£o de schema

### 3.1. Arquivo principal de schema: `infra/sql/init_db.sql`

O schema â€œglobalâ€ (usuÃ¡rios, papÃ©is, org, views, etc.) fica em:

* `infra/sql/init_db.sql`

Logo no topo:

```sql title="init_db.sql (cabeÃ§alho)" showLineNumbers
-- ============================================================================
-- Portal AGEPAR â€” Schema consolidado (PostgreSQL)
-- Idempotente, sem duplicaÃ§Ãµes e sem cÃ³digo de teste.
-- ============================================================================

SET search_path = public;

CREATE EXTENSION IF NOT EXISTS pgcrypto;
CREATE EXTENSION IF NOT EXISTS citext;
```

E mais adiante:

* `CREATE TABLE IF NOT EXISTS ...`
* `ALTER TABLE ... ADD COLUMN IF NOT EXISTS ...`
* `CREATE INDEX IF NOT EXISTS ...`
* Blocos `BEGIN; ... COMMIT;` para seeds idempotentes (org_units, etc).

A ideia:

* VocÃª pode aplicar o arquivo **mÃºltiplas vezes** sem quebrar nada.
* Quando novos campos sÃ£o adicionados, eles aparecem como `ADD COLUMN IF NOT EXISTS`.
* O arquivo funciona tanto para **cluster vazio** quanto para **cluster jÃ¡ existente**.

### 3.2. Schema das automaÃ§Ãµes: `app/db.py`

As tabelas especÃ­ficas das automaÃ§Ãµes sÃ£o criadas por `init_db()` no BFF:

* `apps/bff/app/db.py` â†’ funÃ§Ã£o `init_db()`:

  * `CREATE TABLE IF NOT EXISTS submissions (...)`
  * `CREATE TABLE IF NOT EXISTS automation_audits (...)`
  * `CREATE TABLE IF NOT EXISTS fileshare_items (...)`
  * `CREATE INDEX IF NOT EXISTS ...`
  * `CREATE OR REPLACE FUNCTION touch_updated_at() ...`
  * `DROP TRIGGER IF EXISTS ...; CREATE TRIGGER ...`

Essa funÃ§Ã£o roda no **startup do FastAPI** (`APP.on_event("startup")` em `main.py`) e Ã©
responsÃ¡vel por:

* Garantir que as tabelas â€œmÃ­nimasâ€ de automations existam.
* Aplicar ajustes idempotentes em Ã­ndices/constraints/triggers.

### 3.3. Fluxo recomendado para alteraÃ§Ã£o de schema

Quando for necessÃ¡rio evoluir o schema (ex.: novo Ã­ndice, nova coluna):

1. Atualizar **`infra/sql/init_db.sql`**:

   * adicionar `ALTER TABLE ... ADD COLUMN IF NOT EXISTS`,
   * ajustar constraints, Ã­ndices, views, etc.

2. Se for algo relacionado a automations (`submissions`, `automation_audits`, `fileshare_items`):

   * atualizar tambÃ©m `app/db.py` (para que `init_db()` reflita a mudanÃ§a).

3. Aplicar em ambientes existentes:

   * dev: `psql -f infra/sql/init_db.sql` apontando para o banco dev
     (ou recriar o cluster, se cÃ³modo).
   * homolog/prod: via pipeline ou job com `psql -f` em janela controlada.

4. SÃ³ usar **scripts destrutivos** (DROP COLUMN, renomear coluna, migraÃ§Ã£o pesada de
   dados) em arquivos separados, conscientemente versionados.

> NÃ£o existe hoje integraÃ§Ã£o com Alembic ou outra ferramenta de migraÃ§Ã£o.
> O â€œcontratoâ€ Ã©: **DDL idempotente em SQL + init_db() no BFF**.

---

## 4) Limites e polÃ­ticas de retenÃ§Ã£o

### 4.1. Fileshare â€” TTL, tamanho de upload e limpeza

A automaÃ§Ã£o `fileshare` Ã© o ponto onde os limites estÃ£o mais explÃ­citos.

**TTL (tempo de vida) dos links**:

```python title="fileshare.py â€” TTLs" showLineNumbers
TTL_MAP = {
    "1d": timedelta(days=1),
    "7d": timedelta(days=7),
    "30d": timedelta(days=30),
}
```

* Forms aceitam `ttl` como `"1d" | "7d" | "30d"`.
* Default no endpoint de upload:

  ```python
  ttl: str = Form("7d")
  ```
* A expiraÃ§Ã£o real Ã© calculada como `_utcnow() + TTL_MAP[ttl]`.

**Limite de tamanho de upload**:

```python title="fileshare.py â€” limites de upload" showLineNumbers
MAX_UPLOAD_SIZE = int(os.getenv("MAX_UPLOAD_SIZE", "0"))
UPLOAD_CHUNK_SIZE = int(os.getenv("UPLOAD_CHUNK_SIZE", str(1024 * 1024)))
```

* `MAX_UPLOAD_SIZE`:

  * `0` â†’ **sem limite** na aplicaÃ§Ã£o (vale o limite do servidor/reverso).
  * `>0` â†’ limite em bytes.
* `_save_stream(...)` corta no servidor:

  ```python title="_save_stream" showLineNumbers
  size = 0
  chunk_size = UPLOAD_CHUNK_SIZE if UPLOAD_CHUNK_SIZE > 0 else 1024 * 1024
  with dest.open("wb") as f:
      while True:
          chunk = up.file.read(chunk_size)
          if not chunk:
              break
          f.write(chunk)
          size += len(chunk)
          if MAX_UPLOAD_SIZE and size > MAX_UPLOAD_SIZE:
              ...
              dest.unlink(missing_ok=True)
              raise HTTPException(
                  status_code=413,
                  detail="tamanho do arquivo excede o limite configurado",
              )
  ```

**Limpeza de arquivos expirados**:

```python title="app/db.py â€” limpeza de expirados" showLineNumbers
def fileshare_cleanup_expired(limit: int = 200) -> int:
    """
    Marca como deletados e remove fisicamente arquivos expirados (best-effort).
    """
    now = _utcnow()
    with _pg() as conn, conn.cursor() as cur:
        # SELECT itens expirados e nÃ£o deletados (LIMIT :limit)
        # marca deleted_at e remove o arquivo do disco
        ...
        return count
```

E o endpoint administrativo:

```python title="fileshare.py â€” endpoint de limpeza" showLineNumbers
@router.post("/tasks/cleanup")
def cleanup_now(request: Request, limit: int = 200):
    """
    Executa limpeza imediata de itens expirados.
    """
    user = request.session.get("user")
    if not user:
        raise HTTPException(status_code=401, detail="not authenticated")
    if not (_is_super(user) or "admin" in (user.get("roles") or [])):
        raise HTTPException(status_code=403, detail="admin required")

    deleted = db.fileshare_cleanup_expired(limit=limit)
    return {"expired_deleted": deleted}
```

Resumindo:

* **TTL configurÃ¡vel** (1, 7 ou 30 dias).
* **Limite opcional de tamanho** por upload (`MAX_UPLOAD_SIZE`).
* **Limpeza on-demand** via `/api/automations/fileshare/tasks/cleanup`
  (recomendÃ¡vel automatizar via cron/job em produÃ§Ã£o).

### 4.2. Limites de paginaÃ§Ã£o (submissions e auditoria)

Ainda que o Postgres nÃ£o imponha um limite â€œfÃ­sicoâ€ por tabela, a API aplica limites
de **pÃ¡gina**:

* `list_submissions` (usuÃ¡rio final):

  * parÃ¢metro `limit` (padrÃ£o 50).
* `list_submissions_admin`:

  * `limit` padrÃ£o 100 (sem clamp no DB; o clamp vem do lado FastAPI/Query).
* `controle.py` (`/controle/audits`):

  * `limit: int = Query(default=100, ge=1, le=1000)`.

Ou seja:

* Chamadas normais do frontend dificilmente trarÃ£o mais do que algumas centenas
  de registros por vez.
* Para relatÃ³rios grandes, o caminho recomendado Ã©:

  * iterar com `limit/offset`, **ou**
  * usar endpoints prÃ³prios de exportaÃ§Ã£o (ex.: `controle` gera CSV de auditoria).

### 4.3. RetenÃ§Ã£o de `submissions` e `automation_audits`

Atualmente **nÃ£o hÃ¡** rotina automÃ¡tica de expurgo para:

* `submissions`
* `automation_audits`

A ideia de produto Ã©:

* Manter um **histÃ³rico completo** das automaÃ§Ãµes (execuÃ§Ãµes e eventos) atÃ© que
  a organizaÃ§Ã£o decida uma polÃ­tica de retenÃ§Ã£o (ex.: 5 anos).
* Qualquer polÃ­tica futura deve considerar:

  * eventuais requisitos legais (controles de compras pÃºblicas),
  * volume de dados e custo de armazenamento.

Em termos prÃ¡ticos, para um futuro prÃ³ximo:

* Arquivamento pode ser feito via **job especÃ­fico** (SELECT para arquivo externo +
  DELETE/ARCHIVE em lotes).
* O schema jÃ¡ tem Ã­ndices suficientes para suportar filtros por `created_at`/`at`
  e `kind`, o que facilita cortes por janela de tempo.

---

## 5) Exemplos de fluxo (backup + migraÃ§Ã£o simplificada)

### 5.1. â€œSnapshotâ€ rÃ¡pido antes de alterar schema em dev

```bash title="Passo-a-passo em dev" showLineNumbers
# 1) Dump do banco
docker exec -i portal-agepar-postgres \
  pg_dump -U "${PGUSER:-portal}" "${PGDATABASE:-portal}" \
  > /tmp/portal-dev-before-change.sql

# 2) Aplicar alteraÃ§Ãµes no cÃ³digo:
#    - editar infra/sql/init_db.sql
#    - editar apps/bff/app/db.py (se mexer em automations)

# 3) Subir stack (BFF chamarÃ¡ init_db() automaticamente)
./infra/scripts/dev_up.sh

# 4) Se algo quebrar MUITO, restaurar dump
cat /tmp/portal-dev-before-change.sql | \
  docker exec -i portal-agepar-postgres \
    psql -U "${PGUSER:-portal}" "${PGDATABASE:-portal}"
```

### 5.2. Backup + limpeza de expirados (fileshare)

```bash title="Backup + limpeza (esboÃ§o)" showLineNumbers
# Dump lÃ³gico
docker exec -i portal-agepar-postgres \
  pg_dump -U "${PGUSER:-portal}" "${PGDATABASE:-portal}" \
  > /backup/portal.sql

# Backup dos uploads
docker exec portal-agepar-bff \
  tar czf - /data/uploads > /backup/uploads.tar.gz

# Limpar itens expirados (apenas admin/superuser)
curl -X POST \
  -H "Cookie: session=<session-admin>" \
  http://localhost:8000/api/automations/fileshare/tasks/cleanup
```

---

> _Criado em 2025-12-01_